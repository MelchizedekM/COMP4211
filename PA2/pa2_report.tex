\documentclass{article}
\usepackage{amssymb}
\usepackage{babel}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{framed}
\usepackage{pifont}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{subcaption} 
\usepackage{subcaption} 
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{array}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{tabularx}


\definecolor{codegray}{gray}{0.9}
\lstset{
    backgroundcolor=\color{codegray},
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single
}


\def\ra{\rightarrow}
\def\oo{\infty}
\def\l/{\backslash}
\def\0{\emptyset}
\def\b{\,\,\,}
\def\mm{{\mu^*}}
\def\hm{\mathcal{H}^s}
\def\vm{\nu^*}
\def\cui{\bigcup_{i=1}^\infty}
\def\cai{\bigcap_{i=1}^\infty}
\def\cuj{\bigcup_{j=1}^\infty}
\def\caj{\bigcap_{j=1}^\infty}
\def\sumj{\sum_{j=1}^\infty}
\def\sumi{\sum_{i=1}^\infty}
\def\sumn{\sum_{n=1}^\infty}
\def\px{\mathcal{P}_X}
\def\s{\mathcal{S}}
\def\a{\mathcal{A}}
\def\bs{\mathcal{B}}
\def\lm{\mathcal{L}}
\def\R{\mathbb{R}}
\def\E{\mathbb{E}}
\def\Z{\mathbb{Z}}
\def\m{\mathcal{M}}
\def\rr{\Rightarrow}
\def\tf{$\Rightarrow$}
\def\f{\mathcal{F}}
\def\limn{\lim_{n \rightarrow \infty}}
\def\st{\text{s.t.}}
\def\sums{ \sum_{x \in \s}}

%Ricky Def
\def\baru{\bar{\mu}}
\def\Mbaru{\mathfrak{M}_{\baru}}


\title{COMP4211 PA2 Report} 
\author{Name: Ruiming Min; SID: 20827430; ITSC: rmin}
\date{\today}

\begin{document}

    
\maketitle

\section*{Notice:}
\textbf{Since features of the} \LaTeX \textbf{ file, most of the images and tables are not shown under the discirbation. You can find them by index. Also, you can click the index to jump to the corresponding figure or table.}

\section*{5 Datasets and Data Loaders}

\subsection*{5.3 Dataloader Implementation}

\subsubsection*{[Q1]}
Number of images in COCO dataset: 3557.
Number of images in WikiArt dataset: 7492.

\subsubsection*{[Q2]}
Number of images in PACS train dataset: 1641.
Number of images in PACS test dataset: 2723.

\newpage

\section*{6 Style Transfer}

\subsection*{6.2 Model}

\subsubsection*{[Q3]}
The usage of upsampling layers is \textbf{increase the spatial dimensions (the size of image) of the feature maps obtained from the encoder part of the model.} 
The upsampling layers expend the feature maps by divide one pixel into multiple pixels, and fill the new pixels with the same value as the original pixel.

Since after encoding, the image is represented as a 3D tensor and its 2D shape is much smaller than the original image. 
Therefore, in the decoder, we need the upsampling-re-construct the image-its original size.

\subsubsection*{[Q4]}
Based on the print out of the code (figure \ref{fig:trainable_parameters}), we can find the trainable parameters of the model is 3505219.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{./pic/trainable_para_model1.png}
    \caption{trainable parameters of the model.}
    \label{fig:trainable_parameters}
\end{figure}

\subsubsection*{[Q5]}

Comparison of the encoder and decoder in the model is in table \ref{tab:encoder_decoder_comparison}.


\begin{table}[ht]
    \centering
    \caption{Comparison of Encoder and Decoder}
    \label{tab:encoder_decoder_comparison}
    \begin{tabularx}{\textwidth}{l|XX}
    \toprule
    & \textbf{Encoder} & \textbf{Decoder} \\
    \midrule
    Architecture & Convolutional layers and Max-pooling layers & Convolutional layers and Upsampling layers \\
    Procedure & From 512 filters to 3 filters (the RGB filters), increase the $\frac{1}{8^2}$ of image size from original size to original size. & From 64 filters to 512 filters, decrease the image size from original size to $\frac{1}{8^2}$ of original size. \\
    Input & Image & Features \\
    Output & Features & Image \\
    Weight & Pre-trained and Non-trainable & Non-pre-trained and Trainable \\
    \bottomrule
    \end{tabularx}
    
\end{table}


Since the we need encoder to encode the image and mine the features, but if we only use the encoder, we cannot re-construct the image because the output of the encoder is the feature map of the image.
Thus, we need to use some tools to re-construct the image from the combination of feature map from encoder and the style image (the output of AdaIN layer).
Therefore, we need the decoder to re-construct the image.

As we mentioned in the previous question, the upsampling layers are used to increase the spatial dimensions of the feature maps obtained from the encoder part of the model.
And the convolutional layers are used to extract the features from the feature maps and re-construct the image.


\subsubsection*{[Q6]}
Since in this model, we do not only need the style match our target style, but also need the content-be preserved.
We need to use the content loss to make sure the content of the generated image is similar to the content image.
And we need to use the style loss to make sure the style of the generated image is similar to the style image.
By combining the content loss and style loss, we can get the total loss, which is used to optimize the model to make sure the generated image has the same content and style as the content and style images.

\subsection*{6.4 Training the Style Transfer model}

\subsubsection*{[Q7]}

After 60 epochs (the record of last 5 epochs has been shown on the table \ref{tab:training_loss}), total loss is 12832.387, content loss is 7974.505, and style loss is 4857.882.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Epoch} & \textbf{Total Loss} & \textbf{Content Loss} & \textbf{Style Loss} & \textbf{Iterations(batch\_size = 16)/Time} \\ \hline
    56 & 13208.481 & 8125.815 & 5082.665 & 222/03:44 \\ \hline
    57 & 12974.233 & 8046.959 & 4927.274 & 222/03:31 \\ \hline
    58 & 13357.402 & 8183.614 & 5173.788 & 222/03:30 \\ \hline
    59 & 12692.623 & 7886.791 & 4805.833 & 222/03:29 \\ \hline
    60 & 12832.387 & 7974.505 & 4857.882 & 222/03:31 \\ \hline
    \end{tabular}
    \caption{Epoch-wise training loss metrics for last 5 epochs}
    \label{tab:training_loss}
\end{table}
    

\subsection*{6.5 Inference}

\subsubsection*{[Q8]}

From the figure \ref{fig:part1_inference}, we can see the style transfer examples.
In these comparisons, we can see that the generated images represented the content of the content images very well expect the words in them.
For the style, the generated images are very similar-the style images in color and painting techniques.
However, if the style is very different from the content, the generated images may not be very good (e.g.: picture l).
Moreover, the generated images have some strange textures in some areas, which may be caused by the imbalance of the style data set, i.e., there are too many paintings in the training set.

% input images in a 3*2 grid
\begin{figure}[h!]
    \centering
    % First row of subfigures
    \begin{minipage}{\textwidth}
        \centering
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./data_set/HKUST/1.jpg}
            \caption{Content Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./wikiart/Symbolism/konstantin-bogaevsky_port-of-imaginary-city-1932.jpg}
            \caption{Style Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./part1_inference/output_1_konstantin-bogaevsky_port-of-imaginary-city-1932.jpg}
            \caption{Generated Image}
        \end{subfigure}
    \end{minipage}
    
    \vspace{0.1cm} % This command adds vertical space between the rows
    
    % Second row of subfigures
    \begin{minipage}{\textwidth}
        \centering
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./data_set/HKUST/2.jpg}
            \caption{Content Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./wikiart/Realism/camille-corot_toulon-battleships-dismantled.jpg}
            \caption{Style Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./part1_inference/output_2_camille-corot_toulon-battleships-dismantled.jpg}
            \caption{Generated Image}
        \end{subfigure}
    \end{minipage}
    
    \vspace{0.1cm}

    \begin{minipage}{\textwidth}
        \centering
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./data_set/HKUST/3.jpg}
            \caption{Content Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./wikiart/Post_Impressionism/vincent-van-gogh_red-vineyards-at-arles-1888.jpg}
            \caption{Style Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./part1_inference/output_3_vincent-van-gogh_red-vineyards-at-arles-1888.jpg}
            \caption{Generated Image}
        \end{subfigure}
    \end{minipage}
    
    \vspace{0.1cm}

    \begin{minipage}{\textwidth}
        \centering
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./data_set/HKUST/6.jpeg}
            \caption{Content Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./wikiart/Art_Nouveau_Modern/boris-kustodiev_under-honey-s-harmonica-1927.jpg}
            \caption{Style Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./part1_inference/output_6_boris-kustodiev_under-honey-s-harmonica-1927.jpg}
            \caption{Generated Image}
        \end{subfigure}
    \end{minipage}
    
    \vspace{0.1cm}

    \begin{minipage}{\textwidth}
        \centering
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./data_set/HKUST/14.jpeg}
            \caption{Content Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./wikiart/Early_Renaissance/sandro-botticelli_crucifixion(1).jpg}
            \caption{Style Image}
        \end{subfigure}
        \hfill % This command adds space between the subfigures
        \begin{subfigure}{0.25\textwidth}
            \includegraphics[width=\textwidth]{./part1_inference/output_14_sandro-botticelli_crucifixion(1).jpg}
            \caption{Generated Image}
        \end{subfigure}
    \end{minipage}    
    
    \caption{Example of Style Transfer}
    \label{fig:part1_inference}
\end{figure}

\newpage

\section*{7 Classification Task}

\subsection*{7.2 Analyzing the Dataset}

\subsubsection*{[Q9]}

From the figure \ref{fig:class_distribution}, and the output of the code (table \ref{tab:dataset_distribution}), 
we can see that the highest different between training and testing samples is that there are many type-animal pair only were shown a little in the training dataset but shown a lot in the testing dataset.
Also, the training dataset has a much non-uniform distribution of type-animal pairs, i.e., there are only some type-animal pairs have significant counts and other pairs only have a little data, than testing dataset, which may cause the model to be biased to some type-animal pairs.

\begin{table}[ht]
    \centering
    \caption{Combined Training and Test Data Counts}
    \label{tab:dataset_distribution}
    \begin{tabular}{llrr}
        \toprule
        \multicolumn{2}{c}{Category} & \multicolumn{1}{c}{Training Count} & \multicolumn{1}{c}{Test Count} \\
        \cmidrule(lr){1-2} \cmidrule(lr){3-3} \cmidrule(lr){4-4}
        Label Type & Label Animal & Count & Count \\
        \midrule
        art\_painting & dog & 13 & 119 \\
        art\_painting & elephant & 13 & 89 \\
        art\_painting & giraffe & 231 & 110 \\
        art\_painting & guitar & 10 & 82 \\
        art\_painting & horse & 180 & 90 \\
        art\_painting & house & 11 & 110 \\
        art\_painting & person & 11 & 96 \\
        cartoon & dog & 10 & 95 \\
        cartoon & elephant & 13 & 83 \\
        cartoon & giraffe & 12 & 109 \\
        cartoon & guitar & 121 & 82 \\
        cartoon & horse & 11 & 81 \\
        cartoon & house & 12 & 101 \\
        cartoon & person & 12 & 95 \\
        photo & dog & 10 & 81 \\
        photo & elephant & 13 & 83 \\
        photo & giraffe & 12 & 102 \\
        photo & guitar & 10 & 81 \\
        photo & horse & 11 & 103 \\
        photo & house & 215 & 95 \\
        photo & person & 211 & 110 \\
        sketch & dog & 229 & 112 \\
        sketch & elephant & 217 & 115 \\
        sketch & giraffe & 10 & 104 \\
        sketch & guitar & 9 & 95 \\
        sketch & horse & 8 & 108 \\
        sketch & house & 13 & 80 \\
        sketch & person & 13 & 112 \\
        \bottomrule
    \end{tabular}
    \end{table}

% input images for training and testing
\begin{figure}[h!]
    \centering
% First row of subfigures
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{./pic/class_distribution_1641.png}
        \caption{Train Image}
    \end{subfigure}
    \hfill % This command adds space between the subfigures
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{./pic/class_distribution_2723.png}
        \caption{Test Image}
    \end{subfigure}
    \caption{Class Distribution}
    \label{fig:class_distribution}
\end{figure}


\subsubsection*{[Q10]}
Since the imbalance of training samples, the model may not be able-classify some type-animal pairs very well, i.e., the model will behave better in classifying those pair with more training data into correct cluster. 
For example, since the number of art\_painting-dog is small in the training dataset, the model may not be able to classify the art\_painting-dog as a dog very well. 
But the model may classify the art\_painting-giraffe as a giraffe very well since the number of art\_painting-giraffe is large in the training dataset.

Also, the overall number of training samples of horse and guitar is less than other animal a lot, which may cause the model to be biased to the horse and guitar, and the model may not be able to classify the horse and guitar very well.


\subsection*{7.3 Model Implementation}

\subsubsection*{[Q11]}

Based on the output of the code (figure \ref{fig:trainable_parameters_class}), we can find the trainable parameters of the model is 5609031.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{./pic/trainable_para_model2.png}
    \caption{trainable parameters of the model.}
    \label{fig:trainable_parameters_class}
\end{figure}


\subsection*{7.4 Training the Classification model}

\subsubsection*{[Q12]}

After 160 epochs, the cross-entropy loss is 0.033, the detailed loss summary is shown in the table \ref{tab:cross_entropy_loss}.
\begin{table}[ht]
    \centering
    \caption{Cross-Entropy Loss Summary for Every 10 Epochs}
    \begin{tabular}{cc}
    \toprule
    Epoch & Cross-Entropy Loss \\
    \midrule
    10  & 0.998 \\
    20  & 0.815 \\
    30  & 0.710 \\
    40  & 0.530 \\
    50  & 0.429 \\
    60  & 0.360 \\
    70  & 0.208 \\
    80  & 0.216 \\
    90  & 0.292 \\
    100  & 0.203 \\
    110 & 0.248 \\
    120 & 0.107 \\
    130 & 0.066 \\
    140 & 0.053 \\
    150 & 0.074 \\
    160 & 0.033 \\
    \bottomrule
    \end{tabular}
    \label{tab:cross_entropy_loss}
\end{table}



\subsection*{7.5 Testing Routine}

\subsubsection*{[Q13]}

The accuracy of training dataset is 0.988, and the accuracy of testing dataset is 0.476.

The confusion matrix is shown in the table \ref{tab:confusion_matrix_train} and table \ref{tab:confusion_matrix_test}.

Also, I visualize the confusion matrix in the figure \ref{fig:confusion_matrix_train} and figure \ref{fig:confusion_matrix_test}.

\begin{center}
    \textbf{Confusion Matrix for Train}
    
    \begin{tabular}{c|ccccccc}
    \toprule
    & \multicolumn{7}{c}{Predicted Labels} \\
    \cmidrule(lr){2-8}
    True Labels & dog & elephant & giraffe & guitar & horse & house & person \\
    \midrule
    dog & 249 & 6 & 0 & 0 & 1 & 0 & 2 \\
    elephant & 0 & 251 & 0 & 0 & 0 & 0 & 0 \\
    giraffe & 1 & 1 & 261 & 0 & 0 & 0 & 0 \\
    guitar & 0 & 0 & 0 & 149 & 0 & 0 & 0 \\
    horse & 3 & 0 & 1 & 0 & 205 & 0 & 0 \\
    house & 1 & 1 & 0 & 0 & 0 & 245 & 0 \\
    person & 1 & 0 & 0 & 0 & 2 & 0 & 240 \\
    \bottomrule
    \end{tabular}
    \captionof{table}{Confusion matrix for the training dataset. Accuracy: 0.988}
    \label{tab:confusion_matrix_train}
\end{center}

\begin{center}
    \textbf{Confusion Matrix for Test}
    
    \begin{tabular}{c|ccccccc}
    \toprule
    & \multicolumn{7}{c}{Predicted Labels} \\
    \cmidrule(lr){2-8}
    True Labels & dog & elephant & giraffe & guitar & horse & house & person \\
    \midrule
    dog & 123 & 34 & 72 & 27 & 117 & 22 & 11 \\
    elephant & 46 & 149 & 75 & 10 & 58 & 19 & 13 \\
    giraffe & 76 & 10 & 233 & 19 & 28 & 42 & 17 \\
    guitar & 27 & 8 & 33 & 204 & 47 & 5 & 16 \\
    horse & 91 & 24 & 29 & 35 & 171 & 19 & 11 \\
    house & 12 & 26 & 79 & 32 & 14 & 214 & 9 \\
    person & 44 & 17 & 64 & 30 & 49 & 9 & 200 \\
    \bottomrule
    \end{tabular}
    \captionof{table}{Confusion matrix for the testing dataset. Accuracy: 0.476}
    \label{tab:confusion_matrix_test}
\end{center}



% import confusion matrix
\begin{figure}[h!]
    \centering
    % First row of subfigures
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{./pic/confusion_matrix_1641.png}
        \caption{Train Confusion Matrix}
        \label{fig:confusion_matrix_train}
    \end{subfigure}
    \hfill % This command adds space between the subfigures
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{./pic/confusion_matrix_2723.png}
        \caption{Test Confusion Matrix}
        \label{fig:confusion_matrix_test}
    \end{subfigure}
    \caption{Confusion Matrix}
\end{figure}

\subsubsection*{[Q14]}

The figure \ref{fig:misclassified} shows the misclassified images.
These figures show that the model may not be able to classify those images with complex backgrounds and multiple objects very well (like row1-colum2 and row2-colum5).

Moreover, most of these misclassified data are coming from those type-animal pairs that have less training samples, such as row2-colum7.

Also, it may be hard for the model to classify the images that have unusual styles, such as row1-colum4.

Last but not the least, the style of the images that only have a few information to do the identification, such as all the images of sketch.

\begin{center}
    \noindent 
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r0_p1_1641.jpg}
        dog-elephant
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r0_p5_2723.jpg}
        dog-house
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r0_p6_1641.jpg}
        dog-person
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r1_p2_2723.jpg}
        elephant-giraffe
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r2_p0_2723.jpg}
        giraffe-dog
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r2_p3_2723.jpg}
        giraffe-guitar
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r2_p0_1641.jpg}
        giraffe-dog
    \end{minipage}%

    % 新的一行
    \noindent
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r4_p1_2723.jpg}
        horse-elephant
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r4_p0_1641.jpg}
        dog-horse
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r5_p1_2723.jpg}
        houser-elephant
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r5_p2_2723.jpg}
        house-giraffe
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r5_p4_2723.jpg}
        house-horse
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r6_p0_1641.jpg}
        person-dog
    \end{minipage}%
    \begin{minipage}{0.142\textwidth}
        \includegraphics[width=\linewidth]{./pic/misclassified_r6_p4_1641.jpg}
        person-horse
    \end{minipage}%

    \captionof{figure}{Misclassified Images (the label below is [true label]-[wrong label])}
    \label{fig:misclassified}
\end{center}

\subsection*{7.6 Data Augmentation by Style Transfer}

\subsubsection*{[Q15]}

In figure \ref{fig:label_style}, we can see the example of images with labels and styles.

\begin{figure}[htp]
    \centering
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/dog_art\_painting_0.jpg}
        {dog-art\_painting}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/dog_cartoon_0.jpg}
        {dog-cartoon}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/dog_photo_0.jpg}
        {dog-photo}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/dog_sketch_0.jpg}
        {dog-sketch}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/elephant_art\_painting_0.jpg}
        {elephant-art\_painting}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/elephant_cartoon_0.jpg}
        {elephant-cartoon}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/elephant_photo_0.jpg}
        {elephant-photo}
    \end{minipage}%

    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/elephant_sketch_0.jpg}
        {elephant-sketch}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/giraffe_art\_painting_0.jpg}
        {giraffe-art\_painting}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/giraffe_cartoon_0.jpg}
        {giraffe-cartoon}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/giraffe_photo_0.jpg}
        {giraffe-photo}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/giraffe_sketch_0.jpg}
        {giraffe-sketch}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/guitar_art\_painting_0.jpg}
        {guitar-art\_painting}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/guitar_cartoon_0.jpg}
        {guitar-cartoon}
    \end{minipage}%

    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/guitar_photo_0.jpg}
        {guitar-photo}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/guitar_sketch_0.jpg}
        {guitar-sketch}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/horse_art\_painting_0.jpg}
        {horse-art\_painting}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/horse_cartoon_0.jpg}
        {horse-cartoon}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/horse_photo_0.jpg}
        {horse-photo}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/horse_sketch_0.jpg}
        {horse-sketch}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/house_art\_painting_0.jpg}
        {house-art\_painting}
    \end{minipage}%

    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/house_cartoon_0.jpg}
        {house-cartoon}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/house_photo_0.jpg}
        {house-photo}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/house_sketch_0.jpg}
        {house-sketch}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/person_art\_painting_0.jpg}
        {person-art\_painting}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/person_cartoon_0.jpg}
        {person-cartoon}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/person_photo_0.jpg}
        {person-photo}
    \end{minipage}%%
    \begin{minipage}{0.14285714285714285\linewidth}
        \includegraphics[width=\linewidth]{./classify/derived-files/person_sketch_0.jpg}
        {person-sketch}
    \end{minipage}%


\caption{Example of images with labels and styles.}
\label{fig:label_style}
\end{figure}

\subsection*{7.7 Retraining with Augmented Dataset}

\subsubsection*{[Q16]}

After 160 epochs, the cross-entropy loss is 0.000. The table \ref{tab:cross_entropy_loss_aug} shows the detailed loss summary

\begin{table}[ht]
    \centering
    \caption{Cross-Entropy Loss Summary Every 10 Epochs}
    \begin{tabular}{cc}
    \toprule
    Epoch & Cross-Entropy Loss \\
    \midrule
    10  & 1.055 \\
    20  & 0.826 \\
    30  & 0.550 \\
    40  & 0.338 \\
    50  & 0.259 \\
    60  & 0.193 \\
    70  & 0.071 \\
    80  & 0.096 \\
    90  & 0.047 \\
    100 & 0.004 \\
    110 & 0.003 \\
    120 & 0.110 \\
    130 & 0.000 \\
    140 & 0.000 \\
    150 & 0.000 \\
    160 & 0.000 \\
    \bottomrule
    \end{tabular}
    \label{tab:cross_entropy_loss_aug}
\end{table}


\subsubsection*{[Q17]}
The accuracy of training dataset is 1.000, and the accuracy of testing dataset is 0.524.

The confusion matrix is shown in the table \ref{tab:confusion_matrix_train_aug} and table \ref{tab:confusion_matrix_test_aug}.

Also, I visualize the confusion matrix in the figure \ref{fig:confusion_matrix_train_aug} and figure \ref{fig:confusion_matrix_test_aug}.

\begin{center}
    \textbf{Confusion Matrix for Train}
    
    \begin{tabular}{c|ccccccc}
    \toprule
    & \multicolumn{7}{c}{Predicted Labels} \\
    \cmidrule(lr){2-8}
    True Labels & dog & elephant & giraffe & guitar & horse & house & person \\
    \midrule
    dog & 456 & 0 & 0 & 0 & 0 & 0 & 0 \\
    elephant & 0 & 450 & 0 & 0 & 0 & 0 & 0 \\
    giraffe & 0 & 0 & 464 & 0 & 0 & 0 & 0 \\
    guitar & 0 & 0 & 0 & 346 & 0 & 0 & 0 \\
    horse & 0 & 0 & 0 & 0 & 402 & 0 & 0 \\
    house & 0 & 0 & 0 & 0 & 0 & 446 & 0 \\
    person & 0 & 0 & 0 & 0 & 0 & 0 & 444 \\
    \bottomrule
    \end{tabular}
    \captionof{table}{Confusion matrix for the training dataset. Accuracy: 1.000}
    \label{tab:confusion_matrix_train_aug}
\end{center}

\begin{center}
    \textbf{Confusion Matrix for Test}
    
    \begin{tabular}{c|ccccccc}
    \toprule
    & \multicolumn{7}{c}{Predicted Labels} \\
    \cmidrule(lr){2-8}
    True Labels & dog & elephant & giraffe & guitar & horse & house & person \\
    \midrule
    dog & 143 & 28 & 61 & 37 & 114 & 12 & 12 \\
    elephant & 40 & 152 & 63 & 14 & 69 & 18 & 13 \\
    giraffe & 62 & 15 & 254 & 24 & 25 & 35 & 9 \\
    guitar & 11 & 6 & 35 & 206 & 42 & 13 & 27 \\
    horse & 101 & 33 & 18 & 28 & 170 & 23 & 8 \\
    house & 3 & 5 & 46 & 11 & 29 & 289 & 3 \\
    person & 22 & 14 & 47 & 44 & 51 & 24 & 211 \\
    \bottomrule
    \end{tabular}
    \captionof{table}{Confusion matrix for the testing dataset. Accuracy: 0.524}
    \label{tab:confusion_matrix_test_aug}
\end{center}


        
    
\begin{figure}[h!]
    \centering
    % First row of subfigures
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{./pic/confusion_matrix_3041.png}
        \caption{Train Confusion Matrix}
        \label{fig:confusion_matrix_train_aug}
    \end{subfigure}
    \hfill % This command adds space between the subfigures
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{./pic/confusion_matrix_2723_1.png}
        \caption{Test Confusion Matrix}
        \label{fig:confusion_matrix_test_aug}
    \end{subfigure}
    \caption{Confusion Matrix}
\end{figure}

Comparing the confusion matrix of the original model and the model with augmented dataset, 
we can see that the model with augmented dataset has better performance in both training and testing dataset (increased from 0.476 to 0.524).
This outcome may be caused by the fact that the augmented dataset has more samples and more styles, which can help the model learn more features and be more robust.

\subsubsection*{[Q18]}
This result may be caused by the fact that the augmented dataset has \textbf{more samples} and \textbf{more styles},
which can help the model learn more features and be more robust.

Moreover, the augmented dataset can help the model learn the features of those type-animal pairs that have less training samples,
which means that it can help the model to reduce the bias to some type-animal pairs.

The figure \ref{fig:class_distribution_aug} shows the class distribution after augmentation.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{./pic/class_distribution_3041.png}
    \caption{Class Distribution After Augmentation}
    \label{fig:class_distribution_aug}
\end{figure}



\end{document}
